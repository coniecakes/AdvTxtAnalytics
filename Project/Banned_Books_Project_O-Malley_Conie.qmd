---
title: "Final Project"
author: "Conie O'Malley"
date: "`r Sys.Date()`"
format: 
  pdf: 
    titlepage: true
    toc: true
    toc-depth: 2
    code-block-wrap: true
    number-sections: true
execute:
  echo: true
  freeze: false
  error: false
  jupyter: python3
python:
  version: /Users/coniecakes/anaconda3/envs/datascience/bin/python
---

```{r library chunk}
library(jsonlite)
library(httr)
library(stringdist)
library(quanteda)
data("gutenberg_metadata", package = "gutenbergr")
```

```{r data import}
banned_books_file_path <- "/Users/coniecakes/Library/CloudStorage/OneDrive-Personal/001. Documents - Main/023. Programming Tools/R Studio/AdvTxtAnalytics/Project/data/PEN America's Index of School Book Bans (July 1, 2023 - June 30, 2024).xlsx" # assign file path to variable

banned_books_list <- readxl::read_excel(banned_books_file_path, sheet = "Sorted by Author & Title", skip = 2) # import banned books list

utils::head(banned_books_list, 10) # sanity check to make sure data was read in properly
```

```{r data preparation}
colnames(banned_books_list) <- c("Title", "Author", "Secondary_Author", "Illustrator", "Translator", 
                                "Series_Name", "State", "District", "Date_Removed", "Ban_Status", "Initiating_Action") # assign new column titles

banned_books_cleaned <- banned_books_list %>% 
    dplyr::select(Title, Author, State, District, Date_Removed, Ban_Status, Initiating_Action) %>% # select only relevant columns
    dplyr::mutate(Date_Removed = as.Date(lubridate::my(Date_Removed))) # convert date column to Date class

head(banned_books_cleaned,10) # sanity check

banned_books_cleaned %>% 
    dplyr::summarise(dplyr::across(dplyr::everything(), ~ sum(is.na(.)), .names = "NA_count_{.col}")) # check for NA values in the date column

fl_banned_books_list <- banned_books_cleaned %>% 
    dplyr::filter(State == "Florida") %>% 
    dplyr::distinct(Title, .keep_all = TRUE)

md_banned_books_list <- banned_books_cleaned %>% 
    dplyr::filter(State == "Maryland") %>% 
    dplyr::distinct(Title, .keep_all = TRUE)

ia_banned_books_list <- banned_books_cleaned %>% 
    dplyr::filter(State == "Iowa") %>% 
    dplyr::distinct(Title, .keep_all = TRUE)
```

## Data Sampling

I sampled 10 book titles from the state of Florida's banned books list. I originally wanted to use New York for comparison, but they only had 6 titles, so I selected Maryland as my subgroup comparison.

```{r data sampling}
seed <- 245 # select random seed
set.seed(seed) # set seed for reproducibility

# sample books from Florida & New York
fl_books_sample <- fl_banned_books_list %>% 
    dplyr::sample_n(10) 

md_books_sample <- md_banned_books_list %>% 
    dplyr::sample_n(10)

# print sampled books
print(fl_books_sample)
print(md_books_sample)
```

## Data Collection

### Gutenberg Search

I began to search for data online. I cleaned the book titles from the Florida sample and cleaned the titles from the Gutenberg library (`gutenbergr`) to ensure they matched. I then compared the two lists and found that none of the Florida titles were also in the Gutenberg library. This caused me to pivot to search for any ISBNs from the Florida banned books list sample to attempt to search them in other libraries.
```{r data collection}
# search for titles in gutenberg library
fl_sample_books_titles_cleaned <- fl_books_sample %>% 
    dplyr::select(Title) %>% 
    dplyr::pull() %>% 
    tolower() %>% 
    stringr::str_trim()

gutenberg_titles_cleaned <- gutenbergr::gutenberg_works() %>% 
    dplyr::select(title) %>% 
    dplyr::pull() %>% 
    tolower() %>% 
    stringr::str_trim()

in_gutenberg <- c()

for(i in fl_sample_books_titles_cleaned) {
  if (i %in% gutenberg_titles) {
    in_gutenberg <- c(in_gutenberg, i)
  }
}

in_gutenberg
```

### ISBN Search

I could not obtain any ISBNs from the below function I wrote. I spent a few hours on this, then decided to move on to another method of searching.

```{r isbn search function}
# create isbn search function
get_isbn_google <- function(title) {
    search_url <- paste0("https://www.googleapis.com/books/v1/volumes?q=intitle:", gsub(" ", "+", title))
    response <- httr::GET(search_url)
    if (httr::status_code(response) != 200){
        return("Search unsuccessful")
    }
    book_data <- tryCatch({
        httr::content(response, "text", encoding = "UTF-8") %>% jsonlite::fromJSON()
    }, error = function(e) return(NA))
    if (!"items" %in% names(book_data) || length(book_data$items) == 0) {
        return("No Results Found")
    }
    if (!"items" %in% names(book_data) || !is.list(book_data$items) || length(book_data$items) == 0) {
        return("No Item Exists")
    }
    first_item <- book_data$items[[1]]

    if (!"volumeInfo" %in% names(first_item) || !is.list(first_item$volumeInfo)) {
        return("No Volume Exists")
    }
    volume_info <- first_item$volumeInfo
    if (!"industryIdentifiers" %in% names(volume_info) || !is.list(volume_info$industryIdentifiers)) {
        return("No ISBN Available")  # No ISBN available
    }
    identifiers <- volume_info$industryIdentifiers

    isbn <- NA
    for (id in identifiers) {
        if (id$type == "ISBN_13") {
            isbn <- id$identifier
            break
        } else if (id$type == "ISBN_10") {
            isbn <- id$identifier
        }
    }
    return(isbn)
}

# function test
isbn_example <- get_isbn_google("Slaughterhouse-Five")
print(isbn_example)
```


### Gutenberg Search - Pt. 2

I cleaned all book titles from the Florida banned books list and compared them to the Gutenberg library. My goal is to find a suitable sample of texts here that I can use before reverting to my original plan of using themes and descriptions from the Google Books API.
```{r full gutenberg search}
# create a function to search for titles in a library
full_gutenberg_search <- function(banned_books, gutenberg_titles) {
    matched_books <- banned_books[banned_books %in% gutenberg_titles]
    return(matched_books)
}
```

I have identified titles that I can pull from the Gutenberg library for my project. I am going to take a sample of 10 texts from each, Florida and Iowa, and use them as my sample texts. I ended up getting matches for 16 books from the Iowa banned books list and 53 from Florida. After matching the titles, I will see how many I can downloand and I may need to revise my sample numbers. 
```{r full title search}
fl_books_titles_cleaned <- fl_banned_books_list %>% 
    dplyr::select(Title) %>% 
    dplyr::pull() %>% 
    tolower() %>% 
    stringr::str_trim()

md_books_titles_cleaned <- md_banned_books_list %>% 
    dplyr::select(Title) %>% 
    dplyr::pull() %>% 
    tolower() %>% 
    stringr::str_trim()

ia_books_titles_cleaned <- ia_banned_books_list %>% 
    dplyr::select(Title) %>% 
    dplyr::pull() %>% 
    tolower() %>% 
    stringr::str_trim()

fl_match_list <- full_gutenberg_search(fl_books_titles_cleaned, gutenberg_titles_cleaned)
fl_match_list

md_match_list <- full_gutenberg_search(md_books_titles_cleaned, gutenberg_titles_cleaned)
md_match_list

ia_match_list <- full_gutenberg_search(ia_books_titles_cleaned, gutenberg_titles_cleaned)
ia_match_list
```

```{r title search function}
fuzzy_title_search <- function(book_list) {
    gutenberg_metadata <- gutenbergr::gutenberg_works()
    matched_books <- book_list %>% 
        sapply(function(book) {
            distances <- stringdist::stringdist(book, gutenberg_metadata$title, method = "jw")
            closest_match <- gutenberg_metadata$title[which.min(distances)]
            return(closest_match)   
        })
        return(matched_books)
}
```

```{r data re-sampling}
ia_sample <- sample(ia_match_list, 10)
fl_sample <- sample(fl_match_list, 10)

cat("IA Sample:\n",{ia_sample}, sep="\n")
cat("\nFL Sample:\n",{fl_sample}, sep="\n")
```

```{r fuzzy matching}
# Iowa fuzzy matching
ia_fuzzy_matches <- fuzzy_title_search(ia_sample) # incorrectly selected 1 title
ia_fuzzy_matches

ia_fuzzy_matches_full <- fuzzy_title_search(ia_match_list)

# Florida fuzzy matching
fl_fuzzy_matches <- fuzzy_title_search(fl_sample)
fl_fuzzy_matches

fl_fuzzy_matches_full <- fuzzy_title_search(fl_match_list)
```

I ran into a lot of problems downloading books. After my first pass, I was only able to get 6 / 20, and on my second pass I was only able to get 10/26. I am going to try and download directly from gutenberg's website, but I may need to adjust my sample sizes for subgroup comparison.
```{r download texts}
# retrieve Iowa text ids
ia_gutenberg_ids <- gutenbergr::gutenberg_works() %>%
  dplyr::filter(title %in% ia_fuzzy_matches) %>%
  dplyr::select(gutenberg_id, title)
# correct "Dead End" entry
correct_entry <- gutenbergr::gutenberg_works() %>% 
    dplyr::filter(tolower(title) == "dead end") %>% 
    dplyr::select(gutenberg_id, title)
correct_entry
ia_gutenberg_ids$gutenberg_id[10] <- correct_entry$gutenberg_id
ia_gutenberg_ids$title[10] <- correct_entry$title

ia_gutenberg_ids_full <- gutenbergr::gutenberg_works() %>%
  dplyr::filter(title %in% ia_fuzzy_matches_full) %>%
  dplyr::select(gutenberg_id, title)

# retrieve Florida text ids
fl_gutenberg_ids <- gutenbergr::gutenberg_works() %>%
  dplyr::filter(title %in% fl_fuzzy_matches) %>%
  dplyr::select(gutenberg_id, title)

fl_gutenberg_ids_full <- gutenbergr::gutenberg_works() %>%
  dplyr::filter(title %in% fl_fuzzy_matches_full) %>%
  dplyr::select(gutenberg_id, title)
```

Now I am attempting to download the balance of books from the gutenberg website directly.
```{r gutenberg web search function}
load_gutenberg_text <- function(book_id) {
    url <- paste0("https://www.gutenberg.org/files/", book_id, "/", book_id, "-0.txt")
    response <- httr::GET(url)
    if (status_code(response) == 200) {
        text <- content(response, "text", encoding = "UTF-8")
        return(text)
    } else {
        message(paste("Book ID", book_id, "could not be loaded."))
        return(NULL)
    }
}
```

```{r Florida texts}
# download Florida texts and set up corpus
fl_book_texts <- gutenbergr::gutenberg_download(fl_gutenberg_ids$gutenberg_id)
fl_book_texts <- fl_book_texts %>% 
    dplyr::group_by(gutenberg_id) %>% 
    dplyr::summarise(text = paste0(text, collapse = " "))
# identify missing texts
fl_missing_books <- fl_gutenberg_ids %>%
  dplyr::filter(!(gutenberg_id %in% fl_book_texts$gutenberg_id))

fl_missing_book_texts_list <- list()
for (i in seq_along(fl_missing_books$gutenberg_id)) {
    book_id <- fl_missing_books$gutenberg_id[i]
    book_title <- fl_missing_books$title[i]
    book_text <- load_gutenberg_text(book_id)
    if (!is.null(book_text)) {
        fl_missing_book_texts_list[[as.character(book_id)]] <- data.frame(
            gutenberg_id = book_id,
            text = book_text,
            stringsAsFactors = FALSE
        )
    }
}
fl_missing_book_texts_df <- dplyr::bind_rows(fl_missing_book_texts_list)
fl_book_texts_df <- dplyr::bind_rows(fl_book_texts, fl_missing_book_texts_df) # florida books data frame
```



```{r iowa books data download}
ia_books_text_list <- list()
for (i in seq_along(ia_gutenberg_ids$gutenberg_id)) {
    book_id <- ia_gutenberg_ids$gutenberg_id[i]
    book_title <- ia_gutenberg_ids$title[i]
    book_text <- load_gutenberg_text(book_id)
    if (!is.null(book_text)) {
        ia_books_text_list[[as.character(book_id)]] <- data.frame(
            gutenberg_id = book_id,
            title = book_title,
            text = book_text,
            stringsAsFactors = FALSE
        )
    }
}

ia_book_texts_df <- dplyr::bind_rows(ia_books_text_list)

# replace 1 book that could not be downloaded
missing_books <- ia_gutenberg_ids_full %>%
  dplyr::filter(!(title %in% ia_book_texts_df$title))

if (nrow(missing_books) > 0) {
    ia_additional_sample <- missing_books %>%
        dplyr::slice_sample(n = 1)  
    print(ia_additional_sample) 
} else {
    print("No additional books available for sampling.")
}

ia_additional_sample_text <- load_gutenberg_text(ia_additional_sample$gutenberg_id)
ia_additional_sample_text_df <- data.frame(gutenberg_id = book_id,
            title = book_title,
            text = book_text,
            stringsAsFactors = FALSE)
ia_book_texts_df <- dplyr::bind_rows(ia_book_texts_df, ia_additional_sample_text_df) 

ia_book_texts_df <- ia_book_texts_df %>% 
    dplyr::select(-title) # Iowa banned books list
```

```{r building corpus}
# will complete at a later date
```